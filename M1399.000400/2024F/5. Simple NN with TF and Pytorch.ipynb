{"cells":[{"cell_type":"markdown","metadata":{"id":"f8Jg63H-VWgZ"},"source":["# **Deep Learning Lab: Tensorflow and Pytorch**\n","\n","__author__:Sehyun Park  \n","__email__:ps_hyen@snu.ac.kr\n","\n","In this notebook, we will construct a simple neural network with Tensorflow and Pytorch"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"0yWPMFAp377r","executionInfo":{"status":"ok","timestamp":1730266502125,"user_tz":-540,"elapsed":18465,"user":{"displayName":"­김지수 / 조교수 / 통계학과","userId":"03160174741711253285"}}},"outputs":[],"source":["import numpy as np\n","import tensorflow as tf\n","import torch\n","device = torch.device('cuda:0') if torch.cuda.is_available() is True else 'cpu'"]},{"cell_type":"markdown","metadata":{"id":"08pPEveKsCZA"},"source":["# **With Tensorflow**"]},{"cell_type":"markdown","metadata":{"id":"wmjnTI12WTW8"},"source":["##Efficient code for parameter update by using 'assign'"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"3TZYxcMy5vIE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730266507496,"user_tz":-540,"elapsed":5374,"user":{"displayName":"­김지수 / 조교수 / 통계학과","userId":"03160174741711253285"}},"outputId":"229f999e-ca36-4a33-8f5a-e5ba330744a7"},"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(79.70336, shape=(), dtype=float32)\n","tf.Tensor(72.691284, shape=(), dtype=float32)\n","tf.Tensor(66.84087, shape=(), dtype=float32)\n","tf.Tensor(61.905945, shape=(), dtype=float32)\n","tf.Tensor(57.69779, shape=(), dtype=float32)\n"]}],"source":["# Gradient descent with learning rates 1e-3.\n","N, D_x, D_h1, lr = 10000, 10, 32, 1e-3\n","\n","# Data generation\n","tf.random.set_seed(1004)\n","x = tf.random.normal((N, D_x))\n","y = tf.random.normal((N, 1))\n","w1 = tf.Variable(tf.random.normal((D_x,D_h1)), name=\"w1\")\n","w2 = tf.Variable(tf.random.normal((D_h1, 1)), name=\"w2\")\n","\n","# define model framework\n","def forward(x):\n","  return tf.matmul(tf.maximum(tf.matmul(x, w1), 0), w2)\n","\n","for step in range(5):\n","  with tf.GradientTape() as tape:\n","    y_pred = forward(x)\n","    loss = tf.reduce_mean(tf.reduce_sum((y-y_pred) **2, axis=1))\n","\n","  grad_w1, grad_w2 = tape.gradient(loss, [w1, w2])\n","\n","  w1.assign(w1 - lr*grad_w1)\n","  w2.assign(w2 - lr*grad_w2)\n","  print(loss)"]},{"cell_type":"markdown","metadata":{"id":"1i8rKIxeXi8V"},"source":["##More efficient code for parameter update\n","\n","---\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"cZVeL5VxWnwi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730266507496,"user_tz":-540,"elapsed":7,"user":{"displayName":"­김지수 / 조교수 / 통계학과","userId":"03160174741711253285"}},"outputId":"6dd79736-fe76-4745-bfed-dd7e62c766a4"},"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(79.70336, shape=(), dtype=float32)\n","tf.Tensor(72.691284, shape=(), dtype=float32)\n","tf.Tensor(66.84087, shape=(), dtype=float32)\n","tf.Tensor(61.905945, shape=(), dtype=float32)\n","tf.Tensor(57.69779, shape=(), dtype=float32)\n"]}],"source":["# Gradient descent with learning rates 1e-3.\n","N, D_x, D_h1, lr = 10000, 10, 32, 1e-3\n","\n","# Data generation\n","tf.random.set_seed(1004)\n","x = tf.random.normal((N, D_x))\n","y = tf.random.normal((N, 1))\n","w1 = tf.Variable(tf.random.normal((D_x,D_h1)), name=\"w1\")\n","w2 = tf.Variable(tf.random.normal((D_h1, 1)), name=\"w2\")\n","\n","# define model framework\n","def forward(x):\n","  return tf.matmul(tf.maximum(tf.matmul(x, w1), 0), w2)\n","\n","# set optimizeor\n","# optimizer = tf.keras.optimizers.experimental.SGD(1e-3)\n","optimizer = tf.keras.optimizers.SGD(1e-3)\n","\n","for step in range(5):\n","  with tf.GradientTape() as tape:\n","    y_pred = forward(x)\n","    loss = tf.reduce_mean(tf.reduce_sum((y-y_pred) **2, axis=1))\n","#    optimizer.minimize(loss, [w1, w2], tape)\n","    gradients = tape.gradient(loss, [w1, w2])\n","    optimizer.apply_gradients(zip(gradients, [w1, w2]))\n","  print(loss)"]},{"cell_type":"markdown","metadata":{"id":"0i5dvW6wszNt"},"source":["#**With Pytorch**"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"EG3xaciJP4HD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730266507496,"user_tz":-540,"elapsed":6,"user":{"displayName":"­김지수 / 조교수 / 통계학과","userId":"03160174741711253285"}},"outputId":"44c2e905-bf0e-4333-96e4-347bace95f6a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7b950a11fcd0>"]},"metadata":{},"execution_count":4}],"source":["import torch\n","device = torch.device('cuda:0') if torch.cuda.is_available() is True else 'cpu'\n","torch.manual_seed(1004)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"90B8IyjUF9Nq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730266511224,"user_tz":-540,"elapsed":3733,"user":{"displayName":"­김지수 / 조교수 / 통계학과","userId":"03160174741711253285"}},"outputId":"e61dea3d-e959-46f4-bdcc-811055044c5c"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(1.0414, grad_fn=<MseLossBackward0>)\n","tensor(1.0414, grad_fn=<MseLossBackward0>)\n","tensor(1.0413, grad_fn=<MseLossBackward0>)\n","tensor(1.0413, grad_fn=<MseLossBackward0>)\n","tensor(1.0412, grad_fn=<MseLossBackward0>)\n"]}],"source":["# Data generation\n","N, D_x, D_h1 = 10000, 10, 32\n","x = torch.randn(N, D_x, requires_grad=False)\n","y = torch.randn(N, 1, requires_grad=False)\n","\n","# Construct model by Squential\n","model = torch.nn.Sequential(\n","        torch.nn.Linear(D_x, D_h1),\n","        torch.nn.ReLU(),\n","        torch.nn.Linear(D_h1, 1))\n","\n","criterion = torch.nn.MSELoss()\n","learning_rates = 1e-3\n","optimizer = torch.optim.SGD(model.parameters(), lr = learning_rates)\n","\n","for step in range(5):\n","  y_pred = model(x)\n","  loss = criterion(y_pred, y)\n","  print(loss)\n","\n","  optimizer.zero_grad()\n","  loss.backward() # back-prop\n","  optimizer.step() # update"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"XFRBIncFHUzE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730266511224,"user_tz":-540,"elapsed":5,"user":{"displayName":"­김지수 / 조교수 / 통계학과","userId":"03160174741711253285"}},"outputId":"f1de0d28-5f3d-48bc-d7f4-de49aae537f8"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(1.0400, grad_fn=<MseLossBackward0>)\n","tensor(1.0399, grad_fn=<MseLossBackward0>)\n","tensor(1.0399, grad_fn=<MseLossBackward0>)\n","tensor(1.0399, grad_fn=<MseLossBackward0>)\n","tensor(1.0398, grad_fn=<MseLossBackward0>)\n"]}],"source":["# Construct model by class!\n","\n","\"\"\"\n","model = torch.nn.Sequential(\n","        torch.nn.Linear(D_x, D_h1),\n","        torch.nn.ReLU(),\n","        torch.nn.Linear(D_h1, 1))\n","\"\"\"\n","\n","# 'nn.Module' makes your life happier.\n","class SimpleNet(torch.nn.Module):\n","  def __init__(self, D_x=D_x, D_h1=D_h1):\n","    super(SimpleNet, self).__init__()\n","    self.linear1 = torch.nn.Linear(D_x, D_h1) # fully connected layer\n","    self.linear2 = torch.nn.Linear(D_h1, 1) # fully connected layer\n","\n","  def forward(self, x):\n","    h_relu = self.linear1(x).clamp(min=0)\n","    y_pred = self.linear2(h_relu)\n","    return y_pred\n","\n","\n","model = SimpleNet()\n","criterion = torch.nn.MSELoss()\n","learning_rates = 1e-3\n","optimizer = torch.optim.SGD(model.parameters(), lr = learning_rates)\n","\n","\n","# Gradient descent\n","for _ in range(5):\n","  y_pred = model(x)\n","  loss = criterion(y_pred, y)\n","  print(loss)\n","\n","  optimizer.zero_grad()\n","  loss.backward() # back-prop\n","  optimizer.step() # update\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"8nu0G7uNK8LI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730266512039,"user_tz":-540,"elapsed":819,"user":{"displayName":"­김지수 / 조교수 / 통계학과","userId":"03160174741711253285"}},"outputId":"242121e6-1500-48fc-b609-e8e28824776b"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor(0.9929, grad_fn=<MseLossBackward0>)\n","tensor(0.9929, grad_fn=<MseLossBackward0>)\n","tensor(0.9925, grad_fn=<MseLossBackward0>)\n","tensor(0.9921, grad_fn=<MseLossBackward0>)\n","tensor(0.9916, grad_fn=<MseLossBackward0>)\n"]}],"source":["from torch.utils.data import TensorDataset, DataLoader\n","\n","# Data generation\n","N, D_x, D_h1 = 10000, 10, 32\n","\n","loader = DataLoader(TensorDataset(x,y), batch_size = 100) # Loader style\n","\n","# Stochastic gradient descent\n","for epoch in range(5):\n","  for x_batch, y_batch in loader:\n","    x, y = x_batch, y_batch\n","    y_pred = model(x)\n","    loss = criterion(y_pred, y)\n","\n","    optimizer.zero_grad()\n","    loss.backward() # back-prop\n","    optimizer.step() # update\n","  print(loss)\n"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"nbformat":4,"nbformat_minor":0}